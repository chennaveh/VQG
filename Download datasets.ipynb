{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the first notebook to run:\n",
    "\n",
    "* load CSV as datasets\n",
    "* retrieve the images to local storage\n",
    "* create train,val, test of our dadasets\n",
    "\n",
    "next notebook is VGQ Image_captioning_Inception where will created encoded version of our images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please save the CSV files divided by 3 folders (train,val,test). you can download the CSV files from the link in the README file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data_preprocessing/'\n",
    "org_vqg = 'org_vqg_src/'\n",
    "text_directory='VQg_text/'\n",
    "img_directory = 'VQg_Dataset/VQG_Dataset/'\n",
    "\n",
    "train_file='VQG.trainImages.txt'\n",
    "test_file='VQG.testImages.txt'\n",
    "val_file='VQG.devImages.txt'\n",
    "\n",
    "data_set_part = 'token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "    print(\"You need to STORE your pickle version of csv files in data_preprocessing/org_vqg_src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(directory+org_vqg):\n",
    "    os.mkdir(directory+org_vqg)\n",
    "    print(\"You need to STORE your pickle version of csv files in data_preprocessing/org_vqg_src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(text_directory):\n",
    "    os.mkdir(text_directory)\n",
    "    print(\"For storing info on img, questions and train,test splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_preprocessing/org_vqg_src/*.csv'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory+org_vqg+\"*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_preprocessing/org_vqg_src/train/bing_train_all.csv', 'data_preprocessing/org_vqg_src/train/flickr_train_all.csv', 'data_preprocessing/org_vqg_src/train/coco_train_all.csv', 'data_preprocessing/org_vqg_src/val/flickr_val_all.csv', 'data_preprocessing/org_vqg_src/val/coco_val_all.csv', 'data_preprocessing/org_vqg_src/val/bing_val_all.csv', 'data_preprocessing/org_vqg_src/test/bing_test_all.csv', 'data_preprocessing/org_vqg_src/test/coco_test_all.csv', 'data_preprocessing/org_vqg_src/test/flickr_test_all.csv']\n",
      "2449\n"
     ]
    }
   ],
   "source": [
    "#cuz he create token file of everyything (need to think maybe to turn it trian,val,test also)\n",
    "if data_set_part=='token':\n",
    "    pickle_files =  glob.glob(directory+org_vqg+'train'+'/'+\"*.csv\")+glob.glob(directory+org_vqg+'val'+'/'+\"*.csv\")+glob.glob(directory+org_vqg+'test'+'/'+\"*.csv\")\n",
    "else:\n",
    "    pickle_files =  glob.glob(directory+org_vqg+data_set_part+'/'+\"*.csv\")\n",
    "print(pickle_files)\n",
    "\n",
    "df = pd.read_csv(pickle_files[1])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list_of_imqs = \n",
    " [ \n",
    " \n",
    "    ['image_id', ['q1','q2','q3'] ],\n",
    "    ['image_id',['q1','q2','q3'] ] \n",
    "    \n",
    " ]\n",
    "\n",
    "For every pickle file, \n",
    "\n",
    "    1.open list\n",
    "    2.filter questions ('q1---q2---q3') to ['q1','q2','q3']\n",
    "    3.Append 'img_id' , ['q1','q2','q3'] to list_of_imqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14815\n",
      "14815\n",
      "['1236e320-0e85-42c5-9717-f1afffe3e41e', ['Why is Anne so surprised', 'Why is she excited', 'How much did she get paid to be in this film', 'What movie is this scene from', 'What movie was this from']]\n",
      "VQg_Dataset/VQG_Dataset/1236e320-0e85-42c5-9717-f1afffe3e41e.jpg\n",
      "1236e320-0e85-42c5-9717-f1afffe3e41e.jpg\n"
     ]
    }
   ],
   "source": [
    "def retrieveImg(url, filename):\n",
    "    try:\n",
    "        if not os.path.exists(filename):\n",
    "            pass\n",
    "#             urllib.request.urlretrieve(url, filename) # UNCOMMENT THIS IF U WANT TO DOWNLOAD!!!!!\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print (\"could not retrieve img {0}. Error {1}\".format(url,str(e)))\n",
    "        return False\n",
    "\n",
    "list_of_imqs=[]\n",
    "img_files = []\n",
    "img_file_names=[]\n",
    "for pic_fil in pickle_files:\n",
    "    list_of_imlinkqs = pd.read_csv(pic_fil)\n",
    "    #with open(pic_fil,\"rb\") as fh:       \n",
    "     #   list_of_imlinkqs = pickle.load(fh)  #[['img_id','img_link','q1---q2---q3']]\n",
    "    for instance in list_of_imlinkqs.iterrows():\n",
    "        instance = instance[1]\n",
    "        url = instance['image_url']\n",
    "        filename = \"VQg_Dataset/VQG_Dataset/\"+str(instance['image_id'])+\".jpg\"\n",
    "        \n",
    "        res = retrieveImg(url, filename)\n",
    "        #if succedd to retrieve img add it to training\n",
    "        if res:\n",
    "            #print(instance[1]['questions'])# =  instance[1]\n",
    "            \n",
    "            questions = instance['questions'].split(\"---\")     # Getting multiple questions\n",
    "            questions= [ques[:-1] for ques in questions]  # Removing \"?\" from every question to remove bias\n",
    "            img_id = instance['image_id']\n",
    "            img_files.append(img_directory+str(img_id)+'.jpg')\n",
    "            img_file_names.append(str(img_id)+'.jpg')\n",
    "            list_of_imqs.append([str(img_id),questions])\n",
    "\n",
    "print(len(list_of_imqs))\n",
    "print(len(img_files))\n",
    "print(list_of_imqs[1])\n",
    "print(img_files[1])\n",
    "print(img_file_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## img_question_dict =\n",
    "\n",
    "    key     =   val\n",
    "    img_id  =   ['q1','q2','q3']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What grade is in this classroom',\n",
       " 'How many children attend this class',\n",
       " 'Is this a preschool',\n",
       " 'Why is there only two kids',\n",
       " 'How much is the preschool']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_question_dict={}\n",
    "for img_id,questions in list_of_imqs:\n",
    "    img_question_dict[str(img_id)] = questions\n",
    "\n",
    "img_question_dict[list(img_question_dict.keys())[0]] # present first key of dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img_file_names = \n",
    "\n",
    "[\n",
    "\n",
    "'00051bba-46a4-4aac-876d5c18bb32fc74.jpg',\n",
    "\n",
    " '0043f1ba-1028-4d37-9a7e4f2204978749.jpg',\n",
    " \n",
    " '00472679-97c5-449a-9ece4d55370344f4.jpg'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img_id_file_map = dict()\n",
    "\n",
    "    key      =     val\n",
    "\n",
    "    img_id   =   corresponding image file name\n",
    "    \n",
    "    img_id   =   img_id.jpg\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d9d0f748-0b08-4044-8e43-25eb43da3040.jpg\n",
      "['What grade is in this classroom', 'How many children attend this class', 'Is this a preschool', 'Why is there only two kids', 'How much is the preschool']\n"
     ]
    }
   ],
   "source": [
    "img_id_file_map = dict()\n",
    "\n",
    "for img_fil in img_file_names:\n",
    "    img_id_file_map[str((img_fil.split(\".\"))[0] )] = img_fil \n",
    "\n",
    "\n",
    "print(img_id_file_map[list(img_id_file_map.keys())[0]])\n",
    "print(img_question_dict[list(img_question_dict.keys())[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQG.token.txt file has\n",
    "\n",
    "    img1_.jpg#0 \\t question1\n",
    "    \n",
    "    img1_.jpg#1 \\t question2\n",
    "    \n",
    "    img2_.jpg#0 \\t question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d9d0f748-0b08-4044-8e43-25eb43da3040.jpg#0\\tWhat grade is in this classroom\\nd9d0f748-0b08-4044-8e43-2'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''\n",
    "\n",
    "for img,questions in img_question_dict.items(): # pass on the dict ImgId -> questions\n",
    "    \n",
    "    for indx,question in enumerate(questions): \n",
    "        # for each question create a one line text: <imgPointer # questionIndex \\t question>\n",
    "        try:\n",
    "            img_address = img_id_file_map[img]\n",
    "            text += img_address +\"#\"+str(indx)+\"\\t\"+question+\"\\n\"\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "\n",
    "# text =text[:4]\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_capt_file = 'VQG.token.txt'\n",
    "\n",
    "with open(text_directory+img_capt_file,'w') as fh:\n",
    "    fh.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VQg_Dataset/VQG_Dataset/214ec47b-07fa-4466-9a74-792d0fa08252.jpg',\n",
       " 'VQg_Dataset/VQG_Dataset/bee043fb-4c71-4921-bb78-9d7c0127ac53.jpg',\n",
       " 'VQg_Dataset/VQG_Dataset/737848b3-926c-46d6-81e9-a86172986868.jpg',\n",
       " 'VQg_Dataset/VQG_Dataset/10d52ed2-a7e5-4484-8a31-6a516e7038bb.jpg',\n",
       " 'VQg_Dataset/VQG_Dataset/4ab8e43f-a6a8-415f-94f8-e054397a249f.jpg']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQG.trainImages.txt has\n",
    "\n",
    "    img1.jpg\n",
    "    \n",
    "    img2.jpg\n",
    "    \n",
    "    .. All training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3699"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_size = int( len(img_files) * 0.8)\n",
    "# test_size = int(len(img_files) * 0.1)\n",
    "# val_size = int(len(img_files) * 0.1)\n",
    "data_set_size = len(img_files)\n",
    "# test_size = len(img_files)\n",
    "# val_size = len(img_files)\n",
    "data_set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import numpy as np\n",
    "img_filnames_arr = np.array(img_file_names)\n",
    "np.random.shuffle(img_filnames_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "for img in img_filnames_arr[:data_set_size]:\n",
    "    text+=img+\"\\n\"\n",
    "\n",
    "text = text [:-1]\n",
    "with open(text_directory+data_set_part+'.txt','w') as fh:\n",
    "    fh.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
